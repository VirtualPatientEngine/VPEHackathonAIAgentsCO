{"cells":[{"cell_type":"markdown","metadata":{},"source":"#### A Jupyter notebook log an external/unsupported ML model on MLflow\n\nThis notebook is a simplistic implementation of the tutorial [here](https://mlflow.org/docs/latest/model-registry.html#registering-an-unsupported-machine-learning-model)."},{"cell_type":"markdown","metadata":{},"source":"In some cases, you might use a ML framework without its built-in MLflow Model flavor support. For instance, the [vaderSentiment](https://pypi.org/project/vaderSentiment/) library is a standard Natural Language Processing (NLP) library used for sentiment analysis. Since it lacks a built-in MLflow Model flavor, you cannot log or register the model using MLflow Model fluent APIs.\n\nTo work around this problem, you can create an instance of a `mlflow.pyfunc` model flavor and embed your NLP model inside it, allowing you to save, log or register the model. Once registered, load the model from the Model Registry and score using the predict function.\n\nThe code sections below demonstrate how to create a `PythonFuncModel` class with a `vaderSentiment` model embedded in it, save, log, register, and load from the Model Registry and score. We will use the package `SentimentIntensityAnalyzer` that returns sentiment scores for an input text."},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":"# To use this example, you will need to pip install vaderSentiment (do this in environment)\n# You may also install your model via pip, conda or clone it from GitHub repo, and finally import it here.\nimport os\nimport pandas as pd\n# Import the MLflow package that helps you work with unsupported/external models\nimport mlflow.pyfunc\n# Import the external package\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"},{"cell_type":"markdown","metadata":{},"source":"#### MLflow sync and set up\nIn the following cell, we give a name to the experiment, run, `model_path`, and name with which we want to register the model."},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Experiment with name Test exists. Loading it...\n"]},{"data":{"text/plain":["<Experiment: artifact_location='/tmp/mlflow/db/794067698698294328', creation_time=1714987543542, experiment_id='794067698698294328', last_update_time=1714987543542, lifecycle_stage='active', name='Test', tags={}>"]},"execution_count":96,"metadata":{},"output_type":"execute_result"}],"source":"experiment_name = 'Test'\nrun_name = 'test_vaderSentiment'\nmodel_path = \"vader\" # name of folder in which the model will be saved\nregistered_model_name = \"PyFuncVaderSentiments\" # name with which the model will be registered\n# Remote location of the S3 bucket (on AWS)\n# You should have defined this as a custom key \n# in your environment\ns3_bucket=os.environ['CUSTOM_KEY']\n# Location to store the ML experiments locally\n# This is also the location that you sync with the\n# S3 bucket (see below)\ntracking_uri = '/tmp/mlflow/db/'\n# Sync all contents from the S3 bucket (remote) to the local location\nos.system(f\"aws s3 sync {s3_bucket} {tracking_uri} --quiet\")\n# Let mlflow where you are storing your ML experiments\nmlflow.set_tracking_uri(tracking_uri)\n# If the expr_name is not already in use, create one\ndoes_experiment_exist = mlflow.get_experiment_by_name(experiment_name)\nif not does_experiment_exist:\n    mlflow.create_experiment(experiment_name)\nelse:\n    print (f'Experiment with name {experiment_name} exists. Loading it...')\n# If the expr_name is already in use, use it to track\n# your MLflow\nmlflow.set_experiment(experiment_name)\n"},{"cell_type":"markdown","metadata":{},"source":"#### Define a class and extend from PythonModel\n\nIn the cell below we define a class using the method `PythonModel` from`mlflow.pyfunc`. Within the class we add the package `SentimentIntensityAnalyzer`.\nPerforming this step will bring the external model into `mlflow.pyfunc` framework. You can replance the `SentimentIntensityAnalyzer` with the package from the library you imported.\n\n1. Within the `__init__()` function, we embed the package `SentimentIntensityAnalyzer`. Replace this by the package you'd like to work with. You can change this based on your library and its packages.\n2. Within the `score()` function, we define the code to evaluate the sentiment of an input. Set it up based on your library and its packages.\n3. Within the `predict()` function, we call the `score` function and return its output. Note that `predict()` is a reserved function within the `PythonModel` class, so it is required to have it with the parameters defined below. For most purposes, you will not need to modify it. We will use this function for inference purpose later."},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[],"source":"# Define a class and extend from PythonModel\nclass SocialMediaAnalyserModel(mlflow.pyfunc.PythonModel):\n    def __init__(self):\n        super().__init__()\n        # embed your vader model instance\n        # Replace this by your own model\n        self._analyser = SentimentIntensityAnalyzer()\n\n     # predict the input from the vader sentiment model\n    def _score(self, txt):\n        # Replace this by the functions of your package\n        prediction_scores = self._analyser.polarity_scores(txt)\n        return prediction_scores\n\n    def predict(self, context, model_input, params=None):\n        # Call the score function\n        model_output = self._score(model_input)\n        return model_output"},{"cell_type":"markdown","metadata":{},"source":"#### Test it out with an example"},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'neg': 0.0, 'neu': 0.208, 'pos': 0.792, 'compound': 0.5859}\n","{'neg': 0.762, 'neu': 0.238, 'pos': 0.0, 'compound': -0.4939}\n","{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"]}],"source":"vader_model = SocialMediaAnalyserModel()\n# Positive example\nprint (vader_model._score('Amazing movie'))\n# Negative example\nprint (vader_model._score('Disappointing sequels'))\n# Neutral example\nprint (vader_model._score('T-rex saves the world'))"},{"cell_type":"markdown","metadata":{},"source":"#### Save the model using mlflow.pyfunc"},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Registered model 'PyFuncVaderSentiments' already exists. Creating a new version of this model...\n","Created version '8' of model 'PyFuncVaderSentiments'.\n"]}],"source":"with mlflow.start_run(run_name=run_name) as run:\n    run_id = run.info.run_id # run_id\n    model_path = f\"{model_path}-{run.info.run_id}\" # name with the model should be saved within the run (you can set it to anything)\n    mlflow.log_param(\"algorithm\", \"VADER\")\n    mlflow.pyfunc.save_model(path=model_path, python_model=vader_model)\n    mlflow.pyfunc.log_model(\n        artifact_path=model_path, # path where the model is saved during the run\n        python_model=vader_model, # the ML model\n        registered_model_name=registered_model_name, # name of the model with it is to be registered\n    )\nmlflow.end_run()"},{"cell_type":"markdown","metadata":{},"source":"#### Log metrics\nLog some dummy metrics"},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":"# Create dummy metrics\nmetrics = {\"mse\": 2500.00, \"rmse\": 50.00}\n# Log a batch of metrics to the run_id above\nwith mlflow.start_run(run_id=run_id):\n    mlflow.log_metrics(metrics)"},{"cell_type":"markdown","metadata":{},"source":"#### MLflow sync (IMPORTANT)\nOnce your ML experiment has ended, please sync your local copy with the S3 bucket.\nFailure to do so will lead to loss of experiment logs"},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":"# Sync the local contents with the S3 bucket\nos.system(f\"aws s3 sync {tracking_uri} {s3_bucket} --quiet\")"},{"cell_type":"markdown","metadata":{},"source":"#### Inference\nIn this step we load the model back from MLflow for inference purposes."},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.5719}\n","{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.4767}\n","{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"]}],"source":"# Load our pipeline as a generic python function\nversion_number = 7\nmodel_uri = f\"models:/{registered_model_name}/{version_number}\" # models:/<name_of_registered_model>/<version_number>\nloaded_model = mlflow.pyfunc.load_model(model_uri)\n# inference of a positive example\nprint (loaded_model.predict('happy'))\n# inference of a negative example\nprint (loaded_model.predict('sad'))\n# inference of a neutral example\nprint (loaded_model.predict('sun'))\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}