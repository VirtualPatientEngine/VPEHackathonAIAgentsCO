{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI agents for life sciences","text":"<ul> <li>Made possible by CodeOcean, BioLabs, and TeamVPE at BioMed X sponsored by Sanofi</li> <li>Hackathon flyer</li> <li>Task categories</li> <li>Judging criteria</li> <li>Compute setup</li> <li>Hackathon results</li> </ul>"},{"location":"judging/","title":"Judging for AI agents for life sciences","text":""},{"location":"judging/#1-productivity","title":"1. Productivity","text":"<ul> <li>How productive was your team?</li> <li>How productive were the teams that your team helped?</li> </ul>"},{"location":"judging/#2-task-challenge","title":"2. Task challenge","text":"<ul> <li>How many of the task challenges did your team complete?</li> <li>How well did your team incorporate the expanded use cases?</li> <li>How well were the task challenges aligned with the coaches instructions?</li> </ul>"},{"location":"judging/#3-innovation","title":"3. Innovation","text":"<ul> <li>Did your team come up with a super cool solution that we did not think of?</li> <li>Did your team find another use case not directly stated in the task challenge that provides value?</li> </ul>"},{"location":"judging/#4-reproducibility","title":"4. Reproducibility","text":"<ul> <li>Is there sufficient documentation to repeat what your team did?</li> <li>Are there examples to demonstrate the new functionality that your team added?</li> <li>Are there tests that we can use to verify the new functionality works?</li> </ul>"},{"location":"results/","title":"Results for AI agents for life sciences","text":"<p>\ud83c\udf89 3 AI Agents for Life Science applications were hacked by 7 teams during our past Hackathon in collaboration with Code Ocean, BioLabs Heidelberg, and Sanofi \ud83c\udf89</p>"},{"location":"results/#the-challenge","title":"The challenge","text":"<p>Create an AI Agent to</p> <ol> <li>simulate and ask questions of computational models of disease, </li> <li>process, analyse, and chat with single cell sequencing data, and </li> <li>query and talk to biomedical Knowledge Graphs</li> </ol> <p>using only free form text inputs!</p>"},{"location":"results/#the-result","title":"The result","text":"<p>\u2705 1 OpenSource multi-AI-agent workflow starter kit including code, cloud-native virtual environment, and example data assets was created using Code Ocean and ran on Amazon Web Services (AWS) to kick-start the hackathon.  \u2705 7 teams (21 participants) bravely undertook the immense challenge requiring both technical skill and biomedical knowledge over two days on October 14 to 15. \u2705 3 AI Agents that can add value to Drug Discovery, Drug Development, Biotechnology, and Pharmaceutical research were hacked together and demoed in front of industry judges.</p>"},{"location":"results/#the-winners","title":"The winners","text":""},{"location":"results/#talk2biomodels","title":"\ud83e\udd47 Talk2Biomodels","text":"<ul> <li>Team: Anil Kumar Kanasani, Rakesh Hadne Sreenath, and Maryam Najafian Jazi</li> <li>Judging: Developed a complete AI Agent that can be used as is to download mathematical models from BioModels, run forward simulations from natural language, and ask questions of simuulation results.</li> <li>Next stesp: Adding support for additional LLMs, reverse parameter fitting, and automated species annotations.</li> </ul>"},{"location":"results/#talk2cells","title":"\ud83e\udd48 Talk2Cells","text":"<ul> <li>Team/Consortium: Robin Koch, Mushtaq Ali, Katharina Bosch, Anton Jesu Vikranth, Ashwith Anand Poojary, Farhad Faghihi, Eron Alkanat, Sanjana Balaji Kuttae, and Jaydeep Bhat </li> <li>Judging: An incredible collaboration across 3 teams to develop components needed for single cell clustering, visualization, annotation, and gene perturbation, but ran out of time integrating the components together to create a complete AI agent. </li> <li>Next stesp: Completing the integration of the developed components to have a ready to use AI agent for single cell sequencing analysis, adding additional functionality from cell2sentence, and adding nf-core pipeline integration for processing raw data.</li> </ul>"},{"location":"results/#talk2knowledgegraphs","title":"\ud83e\udd49 Talk2KnowledgeGraphs","text":"<ul> <li>Team: Franscisco Arriaza Gallardo, Andrew Wicks, and \u00d6zge Kayisoglu-Kaya</li> <li>Judging: Developed an AI agent to reason over and visualize an extracted knowledge graph subgraph.</li> <li>Next stesp: Generalizing the Q&amp;A to operate over the entire knowledge graph, adding support for expanding the knowledge graph from user supplied documents, adding support for link prediction to fill in gaps, and adding support for additional embeddings besides text.</li> </ul>"},{"location":"results/#additional-contributions","title":"\ud83c\udf97\ufe0f Additional contributions","text":"<ul> <li>Amazing efforts from Sandeep Chenna, Thulasi Priyadharshini Muruganandam, Niklas Kiermeyer, divakar ravi kumar, and Simge Sengul Babal for contributing components that were integrated into the Talk2Biomodels, Talk2Cells, and Talk2KnowledgeGraphs code post-hackathon.</li> </ul>"},{"location":"results/#shout-out-to-the-people-who-made-it-happen","title":"Shout out to the people who made it happen","text":"<p>\u2b50 Our coaches and judges Lilija Wehling, Ahmad Wisnu Mulyadi, and Gurdeep Singh from TeamVPE at BioMed X Institute, Henrik Cordes, Tommaso Andreani, Ph.D. from Sanofi, and Dr. Christoph Geiger from CodeOcean. \u2b50 Technical wizardry from Shahar Frumkin, Jake Valsamis, Conor Mohan, PhD, Dror Hilman, Ben Even Tsur, Daniel Koster, and Simon Adar from Code Ocean who among many MANY things came to the rescue with additional AWS resources and licenses when we hit our limit during the Hackathon.  \u2b50 Our support team Merve P., Flavia-Bianca Cristian, Mallory Grahnert, Swathi Lingam, Sofija Prikule, Benjamin Raeder, Thomas Rueckle, and Christian Tidona from BioMed X Institute X. \u2b50 The Cadillac of hackathon venues at BioLabs Heidelberg and amazing hosts Ornella Kossi, Ann-Kristin Mueller, and Stefanie Schimmel \u2b50 Our courageous and motivated participants from DKFZ German Cancer Research Center, Heidelberg University, University of Cologne, Karlsruhe Institute of Technology (KIT), Goethe University Frankfurt, SRH Hochschule Heidelberg, and abroad who participated in person and online.</p>"},{"location":"results/#photos","title":"Photos","text":""},{"location":"setup/","title":"Setup for AI agents for life sciences","text":""},{"location":"setup/#infrastructure-and-core-software","title":"Infrastructure and core software","text":"<ul> <li>Cloud infrastructure: Amazon Web Services</li> <li>Computational research platform: Code Ocean</li> <li>Version control: GitHub</li> <li>AI Agent application requirements: Streamlit, Ollama, LangChain, and FAISS</li> </ul>"},{"location":"setup/#setup","title":"Setup","text":""},{"location":"setup/#step-1-introduction-to-our-computational-research-platform-with-code-ocean","title":"Step 1: Introduction to our computational research platform with Code Ocean","text":"<ol> <li>View a short overview video of the Code Ocean platform</li> <li>Review further information in the Code Ocean user guide if needed</li> </ol>"},{"location":"setup/#step-2-enable-simultaneous-capsule-collaboration-with-version-control-using-git-and-github","title":"Step 2: Enable simultaneous capsule collaboration with version control using git and GitHub","text":"<ol> <li>Navigate to our GitHub repository</li> <li> <p>Each team will have their own branch <code>[Team Name]</code> created by the coaches</p> <p>VPEHackathonAIAgentsCOTemplate/main -&gt; VPEHackathonAIAgentsCOTemplate/[Team Name]</p> </li> <li> <p>Each team member will need to add their own pesonal access token in Code Ocean</p> <ol> <li>Follow GitHub instructions to generate a personal access token: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens</li> <li>Save your personal access token! You will also need it when working with Git</li> <li>Then on Code Ocean, click on the <code>account</code> icon on the bottom left side, and go to <code>credentials</code>.</li> <li>Click on <code>\u2295 Add credential</code> and choose <code>GitHub</code>, then add your username (in GitHub) and the token you have created.</li> </ol> </li> <li> <p>Each team member will create their own capsule in Code Ocean by cloning the template repository</p> <ol> <li>Click on the <code>New Capsule</code> button on the top right corner.</li> <li>Select <code>Copy from public Git</code>.</li> <li>Paste the git repository address: (i.e., https://github.com/VirtualPatientEngine/VPEHackathonAIAgentsCOTemplate)</li> <li>Click <code>clone</code></li> <li>The capsule will be cloned within a few seconds.</li> </ol> </li> <li> <p>Each team member will need to attach shared data assets to their own capsule in Code Ocean</p> <ol> <li>In the capsule view, in the data folder in the files tree click \u2699\ufe0fmanage</li> <li>Attach the data-assets by clicking the plus sign (\u2295)</li> <li>The data assets are <code>collections: cellxgene census metadata 2024-04-24</code> and <code>ollama_models_09_2024</code></li> </ol> </li> <li> <p>Individual team members will contribute by syncing with their teams branch (see section step 4 below)</p> </li> </ol> <p>\ud83d\udca1Tip 1. Use the command line <code>terminal</code> in the VS Code editor for running <code>git</code> commands 2. Quick reference of git commands if you forget and the full documentation if typing <code>git --help</code> is not sufficient</p>"},{"location":"setup/#step-3-familiarization-with-the-template-code-ocean-ai-agents-capsule","title":"Step 3: Familiarization with the template Code Ocean AI Agents capsule","text":"<ol> <li>README and overview of the repository</li> <li> <p>The Streamlit Application with three starter examples</p> <p># test that we can run the streamlit app python /code/streamlit_app.py # Run the streamlit app streamlit run /code/streamlit_app.py # Stop the streamlit app [Ctrl] + [C]</p> </li> <li> <p>Extended examples needed for completing the Hackathon challenges</p> </li> <li> <p>Downloading datasets and models (Ollama example)</p> <p># Create the source directory if it doesn't exist mkdir -p /scratch/.ollama # delete the existing symbolic link link rm /root/.ollama # Create the new symbolic link (each write to /root/.ollama will be directed to /scratch/.ollama) ln -s  /scratch/.ollama /root/.ollama # copy the key: cp /data/.ollama/id_ed25519 /scratch/.ollama/id_ed25519 # start the ollama server in the scratch directory cd scratch cd ollama serve # list and pull models ollama list ollama pull llama3.1</p> </li> <li> <p>Downloading datasets and models (Stark example)</p> <p># Create and activate a virtual environment (Optional since we are working in a docker container) python -m venv .venv source .venv/bin/activate # Install stark via pip pip install stark-qa # Download to scratch python from stark_qa import load_skb skb = load_skb(\"prime\", download_processed=True, root=\"/scratch\") # Deactivate virtual environment when done exit() deactivate</p> </li> </ol> <p>\ud83d\udca1Tip 1. Use the <code>Scratch</code> folder for downloading large data files 2. Use the VS Code editor to launch the Ollama server, interact with Streamlit, coding, etc. 3. If you use a virtual envrionment, be sure to add the virtual environment directory to <code>.gitignore</code>! 4. Ollama cheat sheat</p>"},{"location":"setup/#step-4-launching-working-in-and-stopping-the-capsule","title":"Step 4: Launching, working in, and stopping the capsule","text":"<ol> <li>Click the <code>VS Code</code> icon on the top right under <code>Reproducible run</code> to launch a cloud workstation on AWS; Please note that the first time you launch a capsule it will take a few minutes to allocate the resources on AWS.</li> <li> <p>In a new terminal, add the remote team branches</p> <p># add a the VPE remote branches with your teams branch git remote -v git remote add upstream https://[user name]:[token]@github.com/VirtualPatientEngine/VPEHackathonAIAgentsCOTemplate.git git fetch --all --prune</p> </li> <li> <p>Check to see that your teams branch is there e.g., <code>upstream [Team Name]</code>. This is the branch that your team will sync with</p> </li> <li> <p>Create your branch derived from your teams branch</p> <p># check to see that your teams branch is there git branch -v # switch to your teams branch git checkout [Team Name] # create a branch starting from your teams branch for your features (feat) and fixes (fix) git checkout -b [feat or fix]/[name]</p> </li> <li> <p>Hack away \ud83d\ude00</p> </li> <li> <p>Commit your changes</p> <p># stage your changes for the next commit git add . # add your changes to the commit git commit -m \"feat: my cool feature\" # push your changes to your local branch git push origin [feat or fix]/[name]</p> </li> <li> <p>Update your branch with your teams changes</p> <p># fetch all changes from upstream branches git fetch --all --prune # update the local team branch git checkout [Team Name] git pull [Team name] # merge changes from your local team branch into your branch git checkout [feat or fix]/[name] git merge [Team Name]</p> </li> <li> <p>Share your changes with your teams branch</p> <p># ensure your local team branch is up to date git checkout [Team Name] git fetch --all --prune git pull [Team name] # merge your changes (and resolve any conflicts) git merge [feat or fix]/[name] git push upstream [Team Name] # delete your old branch and begin a new one git branch -D [feat or fix]/[name] git checkout -b [feat or fix]/[name]</p> </li> <li> <p>When you are done, please shut down the capsule to save resources! by clicking the <code>red power</code> button on the top left.</p> </li> </ol>"},{"location":"tasks/","title":"Task categories and types for AI agents for life sciences","text":"<p>\u2139\ufe0f Date 2024-10-14 to -15 Location BioLabs Heidelberg and Online</p>"},{"location":"tasks/#category-1-ai-agents-for-computational-modelling-and-simulation","title":"Category 1: AI agents for computational modelling and simulation","text":"<ul> <li>Special software requirements: https://github.com/copasi/basico Documentation </li> <li>Task type 1 and Task type 3 Data for computational modelling: ODE mathematical models in SBML format from BioModels e.g., insulin dynamics, IBD disease dynamics</li> <li>Task type 2 Computational IBD model for parameter fitting: paper and xml file</li> <li>Task type 3 Computational IBD model in non-standard format: paper and MATLAB code </li> <li>Task type 3 Ground truth for MATLAB to SBML conversion: paper, MATLAB equations and SBML file.</li> <li>Data for model annotation: cell ontology, ChEBI, and UniProtKB</li> </ul> <p>\ud83e\uddd1\u200d\ud83c\udfeb Lilija Wehling</p>"},{"location":"tasks/#task-type-1","title":"Task type 1","text":"<ul> <li>Description: Forward simulation of a mathematical model and reporting of the biomarker trajectories and predicted clinical efficacy</li> <li>Input: simulation parameters such as initial concentrations</li> <li>Output: time-course of simulation species</li> </ul>"},{"location":"tasks/#task-type-2","title":"Task type 2","text":"<ul> <li>Description: Reverse fitting of a mathematical model and reporting of the parameter ranges</li> <li>Input: time-course of species</li> <li>Output: fitted model parameters</li> </ul>"},{"location":"tasks/#task-type-3","title":"Task type 3","text":"<ul> <li>Description: Creating a mathematical model from scratch</li> <li>Input: Original article describing the mathematical model and list of equations</li> <li>Output: SBML model with annotated species</li> </ul>"},{"location":"tasks/#category-2-ai-agents-for-omics-and-foundation-models","title":"Category 2: AI agents for omics and foundation models","text":"<ul> <li>Special software requirements: Cell2Sentence</li> <li>Data for analysis: cell by gene</li> <li>Other tools/analyses: differential gene set enrichment analysis using GO, UMAP</li> </ul> <p>\ud83e\uddd1\u200d\ud83c\udfeb Gurdeep Singh</p>"},{"location":"tasks/#task-type-1_1","title":"Task type 1","text":"<ul> <li>Description: Integration of multiple scRNA seq datasets, correction for batch effects, and annotation of cells</li> <li>Input: multiple cell x gene datasets for a particular disease (e.g., Rheumatoid Arthritis, Atopic Dermatitis, Inflammatory Bowel Disease, etx.)</li> <li>Output: UMAP visualization with cell annotation</li> </ul>"},{"location":"tasks/#task-type-2_1","title":"Task type 2","text":"<ul> <li>Description: Simulation of gene perturbation and reporting of the predicted differentially expressed genes using pathway enrichment analysis</li> <li>Input: cell x gene dataset for a particular disease; knockout gene list</li> <li>Output: list of differentially expressed genes and pathway enrichment analysis visualization</li> </ul>"},{"location":"tasks/#category-3-ai-agent-for-biomedical-knowledge-graph-reasoning-and-construction","title":"Category 3: AI agent for Biomedical knowledge graph reasoning and construction","text":"<ul> <li>Special software requirements: PyTorch Geometric and available models through PyG, LLMGraphTransformer, and schema-agnostic graph foundation model (e.g., ULTRA)</li> <li>Biomedical knowledge graph dataset: PrimeKG specifically the subset used in STARK for textual Q&amp;A</li> <li>Other data: PubMed for original articles</li> <li>Graph database: NetworkX</li> </ul> <p>\ud83e\uddd1\u200d\ud83c\udfeb Ahmad Wisnu Mulyadi</p>"},{"location":"tasks/#task-type-1_2","title":"Task type 1","text":"<ul> <li>Description: Knowledge graph Q&amp;A and retrieval of the K-hop subgraph explanations</li> <li>Input: Natural language question (see subset used in https://arxiv.org/abs/2404.13207 for PrimeKG)</li> <li>Output: Ranked nodes answers and visualization of k-hop subgraphs</li> </ul>"},{"location":"tasks/#task-type-2_2","title":"Task type 2","text":"<ul> <li>Description: Disease knowledge graph construction from text using a text-to-graph model to construct the initial knowledge graph and a link prediction model to fill in gaps in the reconstructed knowledge graph</li> <li>Input: List of disease MeSH terms and associated articles from PubMed and list of nodes and edges (same as in PrimeKG)</li> <li>Output: NetworkX representation of the knowledge graph and visualization</li> </ul>"},{"location":"tasks/#task-type-3_1","title":"Task type 3","text":"<ul> <li>Description: Same as type 1 but including protein embeddings from https://www.uniprot.org/help/embeddings and additional vector similarity search of drug targets embeddings </li> <li>Input: Natural language question (see subset used in https://arxiv.org/abs/2404.13207 for PrimeKG)</li> <li>Output: Ranked nodes answers and visualization of k-hop subgraphs</li> </ul>"}]}